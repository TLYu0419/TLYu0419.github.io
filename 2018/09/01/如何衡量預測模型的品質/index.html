<!DOCTYPE html>




<html class="theme-next pisces" lang="zh-tw">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="kXxCbQDO6XajMMXlTzIMZ5reUArY4PDB79OFcuYvw-c" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/Data.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/Data.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/Data.png?v=5.1.4">


  <link rel="mask-icon" href="/Data.png?v=5.1.4" color="#222">





  <meta name="keywords" content="混淆矩陣(Confusion matrix),model selection,R語言," />





  <link rel="alternate" href="/atom.xml" title="TLYu的學習筆記" type="application/atom+xml" />






<meta name="description" content="前些日子有幸參與一場總經理與公司高級長官們的會議，長官們討論著是什麼原因讓公司在近年來取得了如此的成功？ 長官們紛紛表達成功的關鍵因素是行銷策略、通路經營、客戶服務、基站建設、還有帳務管理…等等都有長官提到。 最後總經理卻總結道：「如果是最關鍵的因素，那絕對是人力資源的管理…」 沒錯!我們今天要運用統計分析方法解的就是跟人力資源管理有關的議題!人力資源在勞動市場上的流動是相當常見的現象，但我們並不">
<meta name="keywords" content="混淆矩陣(Confusion matrix),model selection,R語言">
<meta property="og:type" content="article">
<meta property="og:title" content="高薪就能換來忠誠？預測模型的選擇與評估">
<meta property="og:url" content="https://TLYu0419.github.io/2018/09/01/如何衡量預測模型的品質/index.html">
<meta property="og:site_name" content="TLYu的學習筆記">
<meta property="og:description" content="前些日子有幸參與一場總經理與公司高級長官們的會議，長官們討論著是什麼原因讓公司在近年來取得了如此的成功？ 長官們紛紛表達成功的關鍵因素是行銷策略、通路經營、客戶服務、基站建設、還有帳務管理…等等都有長官提到。 最後總經理卻總結道：「如果是最關鍵的因素，那絕對是人力資源的管理…」 沒錯!我們今天要運用統計分析方法解的就是跟人力資源管理有關的議題!人力資源在勞動市場上的流動是相當常見的現象，但我們並不">
<meta property="og:locale" content="zh-tw">
<meta property="og:image" content="https://tlyu0419.github.io/2018/09/01/如何衡量預測模型的品質/%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E9%A0%90%E6%B8%AC%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%93%81%E8%B3%AA/ConfusionMatrix.PNG">
<meta property="og:updated_time" content="2018-09-09T16:24:24.387Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="高薪就能換來忠誠？預測模型的選擇與評估">
<meta name="twitter:description" content="前些日子有幸參與一場總經理與公司高級長官們的會議，長官們討論著是什麼原因讓公司在近年來取得了如此的成功？ 長官們紛紛表達成功的關鍵因素是行銷策略、通路經營、客戶服務、基站建設、還有帳務管理…等等都有長官提到。 最後總經理卻總結道：「如果是最關鍵的因素，那絕對是人力資源的管理…」 沒錯!我們今天要運用統計分析方法解的就是跟人力資源管理有關的議題!人力資源在勞動市場上的流動是相當常見的現象，但我們並不">
<meta name="twitter:image" content="https://tlyu0419.github.io/2018/09/01/如何衡量預測模型的品質/%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E9%A0%90%E6%B8%AC%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%93%81%E8%B3%AA/ConfusionMatrix.PNG">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://TLYu0419.github.io/2018/09/01/如何衡量預測模型的品質/"/>





  <title>高薪就能換來忠誠？預測模型的選擇與評估 | TLYu的學習筆記</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-tw">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">TLYu的學習筆記</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首頁
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            關於
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            標籤
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            歸檔
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            檢索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://TLYu0419.github.io/2018/09/01/如何衡量預測模型的品質/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="TL-Yu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/uploads/IMG_20180501_103746.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="TLYu的學習筆記">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">高薪就能換來忠誠？預測模型的選擇與評估</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">發表於</span>
              
              <time title="創建於" itemprop="dateCreated datePublished" datetime="2018-09-01T11:39:02+08:00">
                2018-09-01
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新於&#58;</span>
              
              <time title="更新於" itemprop="dateModified" datetime="2018-09-10T00:24:24+08:00">
                2018-09-10
              </time>
            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/01/如何衡量預測模型的品質/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/09/01/如何衡量預測模型的品質/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>前些日子有幸參與一場總經理與公司高級長官們的會議，長官們討論著是什麼原因讓公司在近年來取得了如此的成功？<br>
長官們紛紛表達成功的關鍵因素是行銷策略、通路經營、客戶服務、基站建設、還有帳務管理…等等都有長官提到。<br>
最後總經理卻總結道：「如果是最關鍵的因素，那絕對是人力資源的管理…」</p>
<p>沒錯!我們今天要運用統計分析方法解的就是跟人力資源管理有關的議題!人力資源在勞動市場上的流動是相當常見的現象，但我們並不希望績效良好的離開公司，其中如果是傑出員工的離開，對公司來說更是莫大的損失。因此，我們能不能建置一個精準的預測模型，事先掌握公司每位員工的離職率呢？</p>
<h1><a id="more"></a></h1>
<h1>背景知識</h1>
<p>由於模型的預測結果與實際狀況或多或少都會存在不一致的狀況，因此我們可以將這些一致與不一致的狀況繪製成如下表格。其中「預測與實際皆為正」稱作TP，「預測與實際皆為負」稱為TN，「預測為正實際為負」稱為FP，而「預測為負，實際為正」則稱作FN。而如何評價統計模型的品質則是由這四種狀況衍生出相當多的指標，其中我們最常使用的三項指標分別是Accurcy、Precision和Recall rate。</p>
<p><img src="/2018/09/01/如何衡量預測模型的品質/%E5%A6%82%E4%BD%95%E8%A1%A1%E9%87%8F%E9%A0%90%E6%B8%AC%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%93%81%E8%B3%AA/ConfusionMatrix.PNG" alt="ConfusionMatrix"><br>
Accurcy是檢視正確預測在這四種事件中的佔比，計算公式為：(TP+TN)/(TP+TN+FP+FN)。<br>
Precision關注的是被我們預測為正類的樣本中，實際為正的客戶有多少，計算公式為：TP/(TP+FP)。<br>
Recall 在乎的則是實際為正類的樣本中，有多少正類的樣本能被預測出來，計算公式為：TP/(TP+FN)。</p>
<p>然而隨著不同的專案需求，我們並不會總是以0.5作為判定樣本為正類/負類的標準(閥值)。如果FP所付出的代價相當高，我們會將閥值提升；而如果FN的成本很高，我們則會將閥值降低。簡單來說，前者的思考邏輯是「寧可放過，不可錯殺」，而後者則是「寧可錯殺，不可放過」。至於應該如何設定這個閥值，這會隨著不同專案，在經過評估兩種犯錯情境付出的成本後，才能決定我們能接受的結果為何。</p>
<p>接著如果我們把每個閥值的TP、FP結果分別記錄在X與Y軸上，我們將能夠繪製出評估整體模型品質的ROC曲線，而ROC曲線下的面積被稱為AUC值。AUC是經常用來評估整體模型品質的指標，其數值介於0至1。當AUC值為0.5時，表示模型的預測結果相當於隨機猜測的結果（沒有價值），AUC越接近1，表示模型的品質越接近完美的模型，而越接近0則表示比隨機猜測的結果更糟。</p>
<p>如果你對於以上幾種評估模型的指標想要有更進一步的了解的話，在這裡提供兩個維基百科上的補充資料<a href="https://en.wikipedia.org/wiki/Precision_and_recall#F-measure" target="_blank" rel="noopener">Precision and recall</a>與<a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">Receiver operating characteristic</a>。</p>
<h1>資料說明</h1>
<p>我們今天要運用<a href="https://www.kaggle.com/" target="_blank" rel="noopener">kaggle</a>上<a href="https://www.kaggle.com/c/sm" target="_blank" rel="noopener">Human Resources Analytics</a>的資料，在資料中包含了相當豐富的員工資料，我們將運用薪資、工作滿意度、完成幾項專案、近5年是否獲得升遷、服務部門…等等資訊，來預測員工的離職行為。<br>
首先我會運用邏輯回歸與隨機森林兩種演算法建置兩個預測模型。並按照kaggle指定評價模型的Accuracy指標，選擇較佳的模型。接著我會檢視各個因子解釋離職行為的效果，找出影響員工離職的關鍵因素。<br>
在建模的過程中，我們將運用邏輯回歸與隨機森林兩種演算法分別建模，並且進一步比較模型在測試資料中的預測能力。</p>
<h1>安裝與載入套件</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 此部分僅第一次安裝套件的同學執行即可</span><br><span class="line">install.packages(&quot;breakDown&quot;)</span><br><span class="line">install.packages(&quot;tidyverse&quot;)</span><br><span class="line">install.packages(&quot;caret&quot;)</span><br><span class="line">install.packages(&quot;fastDummies&quot;)</span><br><span class="line">install.packages(&quot;magrittr&quot;)</span><br><span class="line"># 載入套件</span><br><span class="line">library(breakDown)</span><br><span class="line">library(tidyverse)</span><br><span class="line">library(caret)</span><br><span class="line">library(fastDummies)</span><br><span class="line">library(magrittr)</span><br></pre></td></tr></table></figure>
<h1>讀取並初步清理資料</h1>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">data(HR_data)</span><br><span class="line">str(HR_data) # 顯示我們的資料集當中有哪些資料</span><br></pre></td></tr></table></figure>
<p>按照輸出的結果顯示，這份資料中共有14,999筆資料，並包含了10個變項。詳細的欄位說明可以到<a href="https://www.kaggle.com/c/sm" target="_blank" rel="noopener">Human Resources Analytics</a>上檢視。這10個變項由上到下分別代表的是工作滿意度、最後一次考核至今的時間(年)、完成專案數量、平均每月工時、在公司服務年數、是否發生過工作事故、員工是否離職、五年內是否有升遷、工作部門、薪資水準。其中工作部門與薪資水準都屬於類別尺度的資料。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&apos;data.frame&apos;:	14999 obs. of  10 variables:</span><br><span class="line"> $ satisfaction_level   : num  0.38 0.8 0.11 0.72 0.37 0.41 0.1 0.92 0.89 0.42 ...</span><br><span class="line"> $ last_evaluation      : num  0.53 0.86 0.88 0.87 0.52 0.5 0.77 0.85 1 0.53 ...</span><br><span class="line"> $ number_project       : int  2 5 7 5 2 2 6 5 5 2 ...</span><br><span class="line"> $ average_montly_hours : int  157 262 272 223 159 153 247 259 224 142 ...</span><br><span class="line"> $ time_spend_company   : int  3 6 4 5 3 3 4 5 5 3 ...</span><br><span class="line"> $ Work_accident        : int  0 0 0 0 0 0 0 0 0 0 ...</span><br><span class="line"> $ left                 : int  1 1 1 1 1 1 1 1 1 1 ...</span><br><span class="line"> $ promotion_last_5years: int  0 0 0 0 0 0 0 0 0 0 ...</span><br><span class="line"> $ sales                : Factor w/ 10 levels &quot;accounting&quot;,&quot;hr&quot;,..: 8 8 8 8 8 8 8 8 8 8 ...</span><br><span class="line"> $ salary               : Factor w/ 3 levels &quot;high&quot;,&quot;low&quot;,&quot;medium&quot;: 2 3 3 2 2 2 2 2 2 2 ...</span><br></pre></td></tr></table></figure>
<p>為了讓後續的分析更方便與穩定，在這裡我簡單對資料進行整理。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">HR_data %&lt;&gt;%</span><br><span class="line">  # 將類別資料轉換為虛擬變項的資料</span><br><span class="line">  dummy_cols(select_columns = c(&quot;sales&quot;,&quot;salary&quot;), remove_most_frequent_dummy = T)%&gt;% </span><br><span class="line">  select(-sales, -salary)%&gt;%</span><br><span class="line">  # 將目標變數重新編碼為Y跟N</span><br><span class="line">  mutate(left = factor(left, c(0,1), c(&quot;N&quot;,&quot;Y&quot;))) %&gt;%</span><br><span class="line">  na.omit()</span><br></pre></td></tr></table></figure>
<p>將資料按照70/30的比例切割為訓練與測試資料，我們將運用訓練資料建置模型，並將模型套用在測試資料來檢視預測模型的解釋效果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># split data to train_set and test_set</span><br><span class="line">set.seed(123)</span><br><span class="line">c &lt;- createDataPartition(y = HR_data$left, p = 0.7,list = F) </span><br><span class="line">train_set &lt;- HR_data[c,]</span><br><span class="line">test_set &lt;- HR_data[-c,]</span><br></pre></td></tr></table></figure>
<h1>Model training</h1>
<p>在這裡我將運用邏輯迴歸與隨機森林兩種演算法來建置模型，並從中挑選出解釋效果較佳的模型</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 邏輯迴歸</span><br><span class="line">model_glm &lt;- train(left ~ .,</span><br><span class="line">                   data = train_set,</span><br><span class="line">                   method = &quot;glmStepAIC&quot;,</span><br><span class="line">                   metric = &quot;ROC&quot;,</span><br><span class="line">                   preProc = c(&quot;zv&quot;,&quot;nzv&quot;,&quot;center&quot;, &quot;scale&quot;),</span><br><span class="line">                   trControl = trainControl(method = &quot;repeatedcv&quot;,</span><br><span class="line">                                            classProbs = T,</span><br><span class="line">                                            summaryFunction = twoClassSummary,</span><br><span class="line">                                            verboseIter = TRUE),</span><br><span class="line">                   family = binomial())</span><br><span class="line"># 隨機森林</span><br><span class="line">model_rf &lt;- train(left ~ .,</span><br><span class="line">                  data = train_set,</span><br><span class="line">                  method = &quot;rf&quot;,</span><br><span class="line">                  metric = &quot;ROC&quot;,</span><br><span class="line">                  preProc = c(&quot;zv&quot;,&quot;nzv&quot;,&quot;center&quot;, &quot;scale&quot;),</span><br><span class="line">                  trControl = trainControl(method = &quot;repeatedcv&quot;,</span><br><span class="line">                                           classProbs = T,</span><br><span class="line">                                           summaryFunction = twoClassSummary,</span><br><span class="line">                                           verboseIter = TRUE),</span><br><span class="line">                  tuneGrid = expand.grid(mtry = floor(sqrt(ncol(train_set)))))</span><br></pre></td></tr></table></figure>
<h1>Model selection</h1>
<p>這裡是本篇文章最核心的內容，在我正式開始說明之前，我先分享個小故事幫助大家了解狀況</p>
<p>以前還在讀書時，我每天出門的第一件事情就是看一下天氣，猜測今天會不會下雨。如果會下雨，我就得多帶把傘，反之則不帶傘。<br>
平常我的「感覺」還滿準確的，當我正確預測天氣的時候，有需要用傘我才會帶，不需要的話就不帶傘(減少包包的重量)。<br>
但是偶爾我的「感覺」也會有預測錯誤的情況，如果我預測會下雨，但實際上沒有下雨的話，我就平白無故增加了包包的重量了；<br>
接著另一種預測錯誤的情境則需要付出較高的代價，因為我預測不會下雨，但實際上卻下雨了，我不只有可能全身淋濕，甚至還有可能造成書籍、手機、筆記型電腦的毀損…</p>
<h2 id="accuracy"><a class="header-anchor" href="#accuracy">¶</a>Accuracy</h2>
<p>那麼我們到底要怎麼進行模型的評估呢？最簡單的方式是檢視Accuracy，也就是用猜對的次數/猜測的總次數。那麼我們就來看一下這份資料在兩種算法下的表現如何吧!</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confusionMatrix(table(predict(model_glm,test_set), test_set$left))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Confusion Matrix and Statistics</span><br><span class="line"></span><br><span class="line">       N    Y</span><br><span class="line">  N 3144  677</span><br><span class="line">  Y  284  394</span><br><span class="line">                                          </span><br><span class="line">               Accuracy : 0.7864          </span><br><span class="line">                 95% CI : (0.7741, 0.7983)</span><br><span class="line">    No Information Rate : 0.7619          </span><br><span class="line">    P-Value [Acc &gt; NIR] : 5.279e-05                          </span><br><span class="line">                  Kappa : 0.3262          </span><br><span class="line"> Mcnemar&apos;s Test P-Value : &lt; 2.2e-16                               </span><br><span class="line">            Sensitivity : 0.9172          </span><br><span class="line">            Specificity : 0.3679          </span><br><span class="line">         Pos Pred Value : 0.8228          </span><br><span class="line">         Neg Pred Value : 0.5811          </span><br><span class="line">             Prevalence : 0.7619          </span><br><span class="line">         Detection Rate : 0.6988          </span><br><span class="line">   Detection Prevalence : 0.8493          </span><br><span class="line">      Balanced Accuracy : 0.6425          </span><br><span class="line">                                          </span><br><span class="line">       &apos;Positive&apos; Class : N</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">confusionMatrix(table(predict(model_rf,test_set), test_set$left))</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Confusion Matrix and Statistics</span><br><span class="line"></span><br><span class="line">       N    Y</span><br><span class="line">  N 3418   31</span><br><span class="line">  Y   10 1040</span><br><span class="line">                                          </span><br><span class="line">               Accuracy : 0.9909          </span><br><span class="line">                 95% CI : (0.9877, 0.9935)</span><br><span class="line">    No Information Rate : 0.7619          </span><br><span class="line">    P-Value [Acc &gt; NIR] : &lt; 2.2e-16                            </span><br><span class="line">                  Kappa : 0.9747          </span><br><span class="line"> Mcnemar&apos;s Test P-Value : 0.001787                                </span><br><span class="line">            Sensitivity : 0.9971          </span><br><span class="line">            Specificity : 0.9711          </span><br><span class="line">         Pos Pred Value : 0.9910          </span><br><span class="line">         Neg Pred Value : 0.9905          </span><br><span class="line">             Prevalence : 0.7619          </span><br><span class="line">         Detection Rate : 0.7597          </span><br><span class="line">   Detection Prevalence : 0.7666          </span><br><span class="line">      Balanced Accuracy : 0.9841          </span><br><span class="line">                                          </span><br><span class="line">       &apos;Positive&apos; Class : N</span><br></pre></td></tr></table></figure>
<p>從以上兩個輸出結果顯示，邏輯回歸的Accuracy值是0.7864；而隨機森林的Accuracy則高達0.9909<br>
但是<br>
因此從Accuracy的角度來看隨機森林的表現趨近於</p>
<p>如果我們有個100%正確的模型，我們就可以完全避免掉錯誤預測帶來的損失，然而我們並不是上帝，沒辦法讓每次的預測都有100%的準確度。<br>
但是我們卻可以用一些方法來提升模型的準確度，例如尋找更多解釋變數來解釋目標變數、嘗試運用不同的演算法…等等。<br>
然而即使如此，我們能做到的也只是提升模型的準確度而已，實際上並不存在100%正確的預測模型。<br>
因此，我們就得進一步精算兩種錯誤預測會帶來的損失，藉以決定我們應該接受多少的錯誤損失。</p>
<p>由於在原始競賽中指定我們是以整體正確率作為評量標準，因此我們…<br>
什麼時候會在意Preceion多一些?什麼時候會在意recall?</p>
<h1>當我們運用訓練集資料完成統計建模之後呢，我們接著就會將模型套用在未參與建模的測試資料上，並檢視模型在測是資料中的預測結果與實際結果是否一致，藉以評估模型的準確度。</h1>
<h1>因為我們運用了2種不同的算法進行統計建模，為了要比較兩種模型的準確度，在這裡我們會透過<a href="https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">混淆矩陣</a>的概念來幫助我們評估與選擇</h1>
<h1></h1>
<h1></h1>
<h1>看氣象報導，提升預測的準確度</h1>
<h1>因此我們在運用統計模型進行決策時，我們除了要不斷提升模型的準確度之外，還得進一步考量兩種犯錯的成本。</h1>
<h1>有時候我們會其中一種的犯錯成本非常小，因此我們會寧願犯這種錯誤，也不願意有犯第二種錯誤的情況發生。就向我寧可把雨具放在包包中，每天上班都帶著出門，也不願意有任何被雨淋濕的狀況出現</h1>
<h1>但是如果我們今天是在</h1>
<h1>在這裡我借用了wiki上說明以上正確/錯誤預測的說明表格</h1>
<h1>用來評價模型的統計指標有相當多，在這裡我們先以競賽網頁中指定的指標選出最佳模型後，接著再跟讀者說明其他指標的意義</h1>
<h1>在這裡我們將模型放入一開始未參與建模的資料中，檢視模型的預測效果，並從中選取最佳模型</h1>
<h1>從以上混淆矩陣的輸出結果我們可以看到在這個案例中是以隨機森林的ACC最高，其次是xgbtree，這兩者差不多，而邏輯回歸則較低</h1>
<h1>那麼在這裡輸出的其他指標又是什麼意義呢?</h1>
<h1>在正式說明之前，我先來跟大家用個生活中的小例子</h1>
<h1>結論與討論</h1>
<p>模型的整體準確度、召回率等等</p>
<p>薪資不是最重要的因素，而是滿意度<br>
那麼什麼又是影響滿意度最重要的原因呢?<br>
有興趣的同學可以自行替換上述的參數，並將滿意度設定為目標變數<br>
帶傘/不帶傘付出的成本相當小，但是工作上預測錯誤成本則會相當大。錯誤的預測會導致…。而我們也不可能把每個人都當作會離開，這會導致維繫的成本大幅提升</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/混淆矩陣-Confusion-matrix/" rel="tag"># 混淆矩陣(Confusion matrix)</a>
          
            <a href="/tags/model-selection/" rel="tag"># model selection</a>
          
            <a href="/tags/R語言/" rel="tag"># R語言</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/09/29/Taste-Cluster/" rel="prev" title="台灣的文化品味如何？階級與音樂品味的多變量分析">
                台灣的文化品味如何？階級與音樂品味的多變量分析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目錄
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            本站概覽
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/uploads/IMG_20180501_103746.jpg"
                alt="TL-Yu" />
            
              <p class="site-author-name" itemprop="name">TL-Yu</p>
              <p class="site-description motion-element" itemprop="description">這裡紀錄了我學習程式、統計的點點滴滴</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">2</span>
                  <span class="site-state-item-name">文章</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">6</span>
                  <span class="site-state-item-name">標籤</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/TLYu0419" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:TLYu0419@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">1.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">2.</span> <span class="nav-text">背景知識</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">3.</span> <span class="nav-text">資料說明</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">4.</span> <span class="nav-text">安裝與載入套件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">5.</span> <span class="nav-text">讀取並初步清理資料</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">6.</span> <span class="nav-text">Model training</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">7.</span> <span class="nav-text">Model selection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#accuracy"><span class="nav-number">7.1.</span> <span class="nav-text">¶Accuracy</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">8.</span> <span class="nav-text">當我們運用訓練集資料完成統計建模之後呢，我們接著就會將模型套用在未參與建模的測試資料上，並檢視模型在測是資料中的預測結果與實際結果是否一致，藉以評估模型的準確度。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">9.</span> <span class="nav-text">因為我們運用了2種不同的算法進行統計建模，為了要比較兩種模型的準確度，在這裡我們會透過混淆矩陣的概念來幫助我們評估與選擇</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">10.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">11.</span> <span class="nav-text"></span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">12.</span> <span class="nav-text">看氣象報導，提升預測的準確度</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">13.</span> <span class="nav-text">因此我們在運用統計模型進行決策時，我們除了要不斷提升模型的準確度之外，還得進一步考量兩種犯錯的成本。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">14.</span> <span class="nav-text">有時候我們會其中一種的犯錯成本非常小，因此我們會寧願犯這種錯誤，也不願意有犯第二種錯誤的情況發生。就向我寧可把雨具放在包包中，每天上班都帶著出門，也不願意有任何被雨淋濕的狀況出現</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">15.</span> <span class="nav-text">但是如果我們今天是在</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">16.</span> <span class="nav-text">在這裡我借用了wiki上說明以上正確/錯誤預測的說明表格</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">17.</span> <span class="nav-text">用來評價模型的統計指標有相當多，在這裡我們先以競賽網頁中指定的指標選出最佳模型後，接著再跟讀者說明其他指標的意義</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">18.</span> <span class="nav-text">在這裡我們將模型放入一開始未參與建模的資料中，檢視模型的預測效果，並從中選取最佳模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">19.</span> <span class="nav-text">從以上混淆矩陣的輸出結果我們可以看到在這個案例中是以隨機森林的ACC最高，其次是xgbtree，這兩者差不多，而邏輯回歸則較低</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">20.</span> <span class="nav-text">那麼在這裡輸出的其他指標又是什麼意義呢?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">21.</span> <span class="nav-text">在正式說明之前，我先來跟大家用個生活中的小例子</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#undefined"><span class="nav-number">22.</span> <span class="nav-text">結論與討論</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">TL-Yu</span>

  
</div>










<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

<span id="busuanzi_container_site_uv">
	本站訪客數<span id="busuanzi_value_site_uv"></span>人次
</span>
        







        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://TLYu0419.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://TLYu0419.github.io/2018/09/01/如何衡量預測模型的品質/';
          this.page.identifier = '2018/09/01/如何衡量預測模型的品質/';
          this.page.title = '高薪就能換來忠誠？預測模型的選擇與評估';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://TLYu0419.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.4"></script>



  

  

  

  
  

  

  

  

</body>
</html>
